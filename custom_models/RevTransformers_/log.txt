dim_mul: tensor([1., 2., 1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.])
head_mul: tensor([1., 2., 1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.])
pool_q: [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [], [], [], [], [], []]
pool_kv: [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]]
stride_q: [[1, 1], [2, 2], [1, 1], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [2, 2], [1, 1], [], [], [], [], [], []]
stride_kv: [[4, 4], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]
MultiScaleBlock(dim=96,dim_out=96,num_heads=1,input_size=[56, 56],mlp_ratio=4.0,qkv_bias=True,drop_path=0.0,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[1, 1],stride_kv=[4, 4],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=96,dim_out=192,num_heads=2,input_size=[56, 56],mlp_ratio=4.0,qkv_bias=True,drop_path=0.006666666828095913,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[2, 2],stride_kv=[2, 2],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=192,dim_out=192,num_heads=2,input_size=[28, 28],mlp_ratio=4.0,qkv_bias=True,drop_path=0.013333333656191826,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[1, 1],stride_kv=[2, 2],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=192,dim_out=384,num_heads=4,input_size=[28, 28],mlp_ratio=4.0,qkv_bias=True,drop_path=0.019999999552965164,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[2, 2],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=384,dim_out=384,num_heads=4,input_size=[14, 14],mlp_ratio=4.0,qkv_bias=True,drop_path=0.02666666731238365,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[1, 1],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=384,dim_out=384,num_heads=4,input_size=[14, 14],mlp_ratio=4.0,qkv_bias=True,drop_path=0.03333333507180214,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[1, 1],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=384,dim_out=384,num_heads=4,input_size=[14, 14],mlp_ratio=4.0,qkv_bias=True,drop_path=0.03999999910593033,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[1, 1],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=384,dim_out=384,num_heads=4,input_size=[14, 14],mlp_ratio=4.0,qkv_bias=True,drop_path=0.046666666865348816,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[1, 1],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=384,dim_out=768,num_heads=8,input_size=[14, 14],mlp_ratio=4.0,qkv_bias=True,drop_path=0.0533333346247673,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[2, 2],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=768,dim_out=768,num_heads=8,input_size=[7, 7],mlp_ratio=4.0,qkv_bias=True,drop_path=0.06000000238418579,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[3, 3],kernel_kv=[3, 3],stride_q=[1, 1],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=768,dim_out=768,num_heads=8,input_size=[7, 7],mlp_ratio=4.0,qkv_bias=True,drop_path=0.06666667014360428,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[],kernel_kv=[3, 3],stride_q=[],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=768,dim_out=768,num_heads=8,input_size=[7, 7],mlp_ratio=4.0,qkv_bias=True,drop_path=0.07333333790302277,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[],kernel_kv=[3, 3],stride_q=[],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=768,dim_out=768,num_heads=8,input_size=[7, 7],mlp_ratio=4.0,qkv_bias=True,drop_path=0.07999999821186066,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[],kernel_kv=[3, 3],stride_q=[],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=768,dim_out=768,num_heads=8,input_size=[7, 7],mlp_ratio=4.0,qkv_bias=True,drop_path=0.08666667342185974,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[],kernel_kv=[3, 3],stride_q=[],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=768,dim_out=768,num_heads=8,input_size=[7, 7],mlp_ratio=4.0,qkv_bias=True,drop_path=0.09333333373069763,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[],kernel_kv=[3, 3],stride_q=[],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MultiScaleBlock(dim=768,dim_out=768,num_heads=8,input_size=[7, 7],mlp_ratio=4.0,qkv_bias=True,drop_path=0.10000000149011612,norm_layer=functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06),kernel_q=[],kernel_kv=[3, 3],stride_q=[],stride_kv=[1, 1],mode=conv,has_cls_embed=False,pool_first=False,rel_pos_spatial=True,rel_pos_zero_init=False,residual_pooling=True,dim_mul_in_att=True,)
MViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=[7, 7], stride=[4, 4], padding=[3, 3])
  )
  (blocks): ModuleList(
    (0): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[4, 4], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[4, 4], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (1): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
      (proj): Linear(in_features=96, out_features=192, bias=True)
      (pool_skip): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=1, ceil_mode=False)
    )
    (2): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (3): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
      (proj): Linear(in_features=192, out_features=384, bias=True)
      (pool_skip): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=1, ceil_mode=False)
    )
    (4): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (5): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (6): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (7): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (8): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
      (proj): Linear(in_features=384, out_features=768, bias=True)
      (pool_skip): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=1, ceil_mode=False)
    )
    (9): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (10): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (11): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (12): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (13): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (14): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (15): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_k): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv2d(96, 96, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): TransformerBasicHead(
    (projection): Linear(in_features=768, out_features=1000, bias=True)
    (act): Softmax(dim=1)
  )
)

MViT,  Input: torch.Size([4, 1, 168, 40])
PatchEmbed,  Input: torch.Size([4, 1, 168, 40])
MultiScaleBlock,  Input: torch.Size([4, 420, 96]), (42, 10)
MultiScaleBlock,  Input: torch.Size([4, 420, 96]), (42, 10)
MultiScaleBlock,  Input: torch.Size([4, 105, 192]), (21, 5)
MultiScaleBlock,  Input: torch.Size([4, 105, 192]), (21, 5)
MultiScaleBlock,  Input: torch.Size([4, 33, 384]), (11, 3)
MultiScaleBlock,  Input: torch.Size([4, 33, 384]), (11, 3)
MultiScaleBlock,  Input: torch.Size([4, 33, 384]), (11, 3)
MultiScaleBlock,  Input: torch.Size([4, 33, 384]), (11, 3)
MultiScaleBlock,  Input: torch.Size([4, 33, 384]), (11, 3)
MultiScaleBlock,  Input: torch.Size([4, 12, 768]), (6, 2)
MultiScaleBlock,  Input: torch.Size([4, 12, 768]), (6, 2)
MultiScaleBlock,  Input: torch.Size([4, 12, 768]), (6, 2)
MultiScaleBlock,  Input: torch.Size([4, 12, 768]), (6, 2)
MultiScaleBlock,  Input: torch.Size([4, 12, 768]), (6, 2)
MultiScaleBlock,  Input: torch.Size([4, 12, 768]), (6, 2)
MultiScaleBlock,  Input: torch.Size([4, 12, 768]), (6, 2)
TransformerBasicHead,  Input: torch.Size([4, 768])
TransformerBasicHead,  Output: torch.Size([4, 1000])
